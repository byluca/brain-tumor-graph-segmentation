{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8fc6a6c-cf75-4818-a864-ef0873240e89",
   "metadata": {},
   "source": [
    "## **Settings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa1ce9-c2c1-49af-8bb6-89463533cbd6",
   "metadata": {},
   "source": [
    "- Importazione delle librerie necessarie e impostazione dei percorsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5af361a-2d8a-4414-a529-fee416771595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazione delle librerie necessarie\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from sys import platform\n",
    "\n",
    "# Impostazione dei percorsi\n",
    "_base_path = '\\\\'.join(os.getcwd().split('\\\\')[:-1]) + '\\\\' if platform == 'win32' else '/'.join(os.getcwd().split('/')[:-1]) + '/'\n",
    "sys.path.append(_base_path)\n",
    "\n",
    "# Importare le librerie necessarie\n",
    "from monai.utils import set_determinism\n",
    "from src.helpers.config import get_config\n",
    "from src.models.gnn import GraphSAGE, GAT, ChebNet\n",
    "from torch_geometric.explain import Explainer, ModelConfig, ThresholdConfig\n",
    "# Rimuoviamo PGExplainer e usiamo solo GNNExplainer\n",
    "from torch_geometric.explain.algorithm import GNNExplainer\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0accd3-c6f5-4ac5-937f-50ba1b287c4d",
   "metadata": {},
   "source": [
    "- Definizione dei percorsi per i dati, grafi, modelli salvati e report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7d97e8-3b46-49f1-bd77-6f4feee55eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dei percorsi\n",
    "_config = get_config()\n",
    "data_path = os.path.join(_base_path, _config.get('DATA_FOLDER'))\n",
    "graph_path = os.path.join(data_path, _config.get('GRAPH_FOLDER'))\n",
    "saved_path = os.path.join(_base_path, _config.get('SAVED_FOLDER'))\n",
    "reports_path = os.path.join(_base_path, _config.get('REPORT_FOLDER'))\n",
    "logs_path = os.path.join(_base_path, _config.get('LOG_FOLDER'))\n",
    "\n",
    "if platform == 'win32':\n",
    "    data_path = data_path.replace('/', '\\\\')\n",
    "    graph_path = graph_path.replace('/', '\\\\')\n",
    "    saved_path = saved_path.replace('/', '\\\\')\n",
    "    reports_path = reports_path.replace('/', '\\\\')\n",
    "    logs_path = logs_path.replace('/', '\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36ed47-81eb-47b2-a851-8c8a5e0cc6f3",
   "metadata": {},
   "source": [
    "- Impostazione dei seed per la riproducibilità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71af94e-3fea-4bbf-b2ac-48ed3bff8496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1655bcf5390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impostare un seed per la riproducibilità\n",
    "set_determinism(seed=3)\n",
    "random.seed(3)\n",
    "np.random.seed(3)\n",
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfd3f8-362c-499e-a8b9-d2b932fab8f8",
   "metadata": {},
   "source": [
    "## **Definizione del modello**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa40f6-c30a-4d55-b84e-466a9e8e6744",
   "metadata": {},
   "source": [
    "- Configurazione dei parametri del modello e creazione dell'istanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec20edd-5bcf-463c-ae00-4ae8b2c62178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello creato: ChebNet\n"
     ]
    }
   ],
   "source": [
    "# Definizione dei parametri del modello\n",
    "# PARAMETRI CONDIVISI\n",
    "num_node_features = 50          # Dimensione feature di input\n",
    "num_classes = 4                 # Numero di classi di output\n",
    "lr = 1e-4                       # Learning rate per l'ottimizzatore\n",
    "weight_decay = 1e-5             # Weight decay per l'ottimizzatore\n",
    "dropout = .0                    # Probabilità di dropout (per features)\n",
    "hidden_channels = [512, 512, 512, 512, 512, 512, 512]  # Unità nascoste\n",
    "\n",
    "# PARAMETRI GRAPHSAGE\n",
    "aggr = 'mean'                   # Operazione di aggregazione\n",
    "\n",
    "# PARAMETRI GAT\n",
    "heads = 14                      # Numero di attention heads\n",
    "attention_dropout = .1          # Probabilità di dropout (per attention)\n",
    "\n",
    "# PARAMETRI CHEBNET\n",
    "k = 4                           # Ordine polinomiale Chebyshev\n",
    "\n",
    "# Creazione del modello da utilizzare\n",
    "model = ChebNet(\n",
    "    in_channels=num_node_features,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=num_classes,\n",
    "    dropout=dropout,\n",
    "    K=k\n",
    ")\n",
    "print(f\"Modello creato: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d10b8-dd50-43c4-b947-23887303dd22",
   "metadata": {},
   "source": [
    "## **Caricamento dei dati**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6bd12-3dd6-42ba-b997-92d849db82e1",
   "metadata": {},
   "source": [
    "- Funzione per la ricerca e il caricamento di un grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faaa5c4f-1f74-45c3-841b-ee904e28cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per trovare e caricare un grafo per l'analisi\n",
    "def find_and_load_graph(subject_id=None):\n",
    "    \"\"\"\n",
    "    Trova e carica un grafo per l'analisi.\n",
    "    \n",
    "    Args:\n",
    "        subject_id: ID specifico del soggetto da caricare, se None ne verrà scelto uno casualmente\n",
    "        \n",
    "    Returns:\n",
    "        data: Il grafo caricato\n",
    "        subject_id: L'ID del soggetto caricato\n",
    "    \"\"\"\n",
    "    if subject_id is None:\n",
    "        # Trova le cartelle dei soggetti che contengono grafi\n",
    "        subject_dirs = [d for d in os.listdir(graph_path) if os.path.isdir(os.path.join(graph_path, d))]\n",
    "        valid_subjects = []\n",
    "        \n",
    "        # Cerca i primi 10 soggetti che hanno file .graph\n",
    "        for subject in subject_dirs[:100]:  # Limita la ricerca per efficienza\n",
    "            graph_file = os.path.join(graph_path, subject, f\"{subject}.graph\")\n",
    "            if os.path.isfile(graph_file):\n",
    "                valid_subjects.append(subject)\n",
    "                if len(valid_subjects) >= 10:\n",
    "                    break\n",
    "        \n",
    "        if not valid_subjects:\n",
    "            raise FileNotFoundError(\"Nessun grafo trovato nella directory data/graphs/\")\n",
    "        \n",
    "        # Scegli un soggetto casuale\n",
    "        subject_id = random.choice(valid_subjects)\n",
    "    \n",
    "    # Carica il grafo\n",
    "    graph_file = os.path.join(graph_path, subject_id, f\"{subject_id}.graph\")\n",
    "    if not os.path.isfile(graph_file):\n",
    "        raise FileNotFoundError(f\"File grafo non trovato per il soggetto {subject_id}\")\n",
    "    \n",
    "    print(f\"Caricamento grafo: {graph_file}\")\n",
    "          \n",
    "    data = torch.load(graph_file, weights_only=False)\n",
    "    \n",
    "    return data, subject_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464d271-f0c2-4bf1-a7cb-e06e39fc7adc",
   "metadata": {},
   "source": [
    "- Caricamento di un grafo specifico con alta accuratezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede80b46-365f-4cb1-aee5-447827f19dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento grafo: C:\\Users\\gianluca\\Desktop\\brain-tumor-graph-segmentation-main\\data\\graphs\\BraTS-GLI-01166-000\\BraTS-GLI-01166-000.graph\n",
      "Grafo caricato con successo: BraTS-GLI-01166-000\n",
      "Numero di nodi: 2607\n",
      "Numero di archi: 26070\n",
      "Numero di features per nodo: 50\n"
     ]
    }
   ],
   "source": [
    "# Carica un grafo specifico con alta accuratezza (come visto nel precedente test)\n",
    "subject_id = \"BraTS-GLI-01166-000\"  # Grafo con accuratezza 100%\n",
    "try:\n",
    "    data, subject_id = find_and_load_graph(subject_id)\n",
    "    print(f\"Grafo caricato con successo: {subject_id}\")\n",
    "    print(f\"Numero di nodi: {data.x.shape[0]}\")\n",
    "    print(f\"Numero di archi: {data.edge_index.shape[1]}\")\n",
    "    print(f\"Numero di features per nodo: {data.x.shape[1]}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Errore: {e}\")\n",
    "    print(\"Tentativo di caricamento di un grafo alternativo...\")\n",
    "    data, subject_id = find_and_load_graph(None)\n",
    "    print(f\"Grafo alternativo caricato: {subject_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe672fa-a019-4d18-9ce6-8d907246898a",
   "metadata": {},
   "source": [
    "## **Caricamento del Modello Pre-addestrato**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b6abb-d4ce-4e26-bfef-26c203cb9b32",
   "metadata": {},
   "source": [
    "- Ricerca e caricamento del modello ChebNet migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d171c2-3ed4-4deb-b9ea-1e59d39d9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizzo del modello pre-addestrato: CHEBNET_1739029370_best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChebNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): ChebConv(50, 512, K=4, normalization=sym)\n",
       "    (1-6): 6 x ChebConv(512, 512, K=4, normalization=sym)\n",
       "    (7): ChebConv(512, 4, K=4, normalization=sym)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carica il modello pre-addestrato\n",
    "model_files = [f for f in os.listdir(saved_path) if 'CHEBNET' in f and f.endswith('_best.pth')]\n",
    "if not model_files:\n",
    "    raise FileNotFoundError(\"Nessun modello ChebNet pre-addestrato trovato nella directory saved/\")\n",
    "\n",
    "latest_model = model_files[-1]\n",
    "print(f\"Utilizzo del modello pre-addestrato: {latest_model}\")\n",
    "model.load_state_dict(torch.load(os.path.join(saved_path, latest_model), map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728b6b2-381a-4dbe-830c-7263367dad6f",
   "metadata": {},
   "source": [
    "## **Valutazione dell'Accuratezza**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090dbc4-093b-4a07-b485-f3c7e329e2f9",
   "metadata": {},
   "source": [
    "- Verifica dell'accuratezza del modello sul grafo caricato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de29b545-0319-4939-9a6d-3267fa0fc109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG INFORMAZIONI DATI ---\n",
      "Tipo di data.y: <class 'torch.Tensor'>\n",
      "Forma di data.y: torch.Size([2607])\n",
      "Tipo di dati di data.y: torch.float32\n",
      "Tipo di predicted_labels: <class 'torch.Tensor'>\n",
      "Forma di predicted_labels: torch.Size([2607])\n",
      "Tipo di dati di predicted_labels: torch.int64\n",
      "Primo elemento di data.y: 0.0\n",
      "Forma del primo elemento di data.y: torch.Size([])\n",
      "--------------------------------\n",
      "\n",
      "Accuratezza sul grafo BraTS-GLI-01166-000: 1.0000\n",
      "Distribuzione classi predette: [2550   16    4   37]\n"
     ]
    }
   ],
   "source": [
    "# Verifica dell'accuratezza sul grafo caricato\n",
    "with torch.no_grad():\n",
    "    outputs = model(data.x, data.edge_index.type(torch.int64))\n",
    "    predicted_labels = outputs.argmax(dim=1)\n",
    "    \n",
    "    # Visualizza le informazioni per debug\n",
    "    print(\"\\n--- DEBUG INFORMAZIONI DATI ---\")\n",
    "    print(f\"Tipo di data.y: {type(data.y)}\")\n",
    "    if hasattr(data.y, 'shape'):\n",
    "        print(f\"Forma di data.y: {data.y.shape}\")\n",
    "    if hasattr(data.y, 'dtype'):\n",
    "        print(f\"Tipo di dati di data.y: {data.y.dtype}\")\n",
    "    print(f\"Tipo di predicted_labels: {type(predicted_labels)}\")\n",
    "    print(f\"Forma di predicted_labels: {predicted_labels.shape}\")\n",
    "    print(f\"Tipo di dati di predicted_labels: {predicted_labels.dtype}\")\n",
    "    \n",
    "    try:\n",
    "        # Prova a estrarre il primo elemento di data.y per vedere se funziona\n",
    "        if len(data.y) > 0:\n",
    "            first_y = data.y[0]\n",
    "            print(f\"Primo elemento di data.y: {first_y}\")\n",
    "            if hasattr(first_y, 'shape'):\n",
    "                print(f\"Forma del primo elemento di data.y: {first_y.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'accesso a data.y: {e}\")\n",
    "    \n",
    "    print(\"--------------------------------\\n\")\n",
    "    \n",
    "    # Crea un tensore delle classi da usare, contenente le predizioni del modello\n",
    "    node_classes = predicted_labels.clone()\n",
    "    \n",
    "    # Calcola l'accuratezza usando predicted_labels e data.y se possibile\n",
    "    try:\n",
    "        accuracy = (predicted_labels == data.y).float().mean().item()\n",
    "        print(f\"Accuratezza sul grafo {subject_id}: {accuracy:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Impossibile calcolare l'accuratezza usando data.y: {e}\")\n",
    "        print(\"Usando solo le predizioni per l'analisi\")\n",
    "    \n",
    "    class_counts = torch.bincount(predicted_labels, minlength=num_classes)\n",
    "    print(f\"Distribuzione classi predette: {class_counts.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf0313-c8a3-4c30-a25f-654d6f5a209c",
   "metadata": {},
   "source": [
    "## **Implementazione di GNNExplainer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38de420-115c-4678-b2e2-6d71ea0b8e70",
   "metadata": {},
   "source": [
    "- Configurazione e applicazione di GNNExplainer per la spiegabilità del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc53ec29-8fe7-4efc-bab9-500060931cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dei nomi delle classi\n",
    "# L'indice della lista corrisponde al valore numerico della classe.\n",
    "# Assicurati che questo ordine sia coerente con le etichette nel tuo dataset BraTS\n",
    "# e con l'output del tuo modello GNN.\n",
    "\n",
    "classes = [\n",
    "    \"Sano/Background\",      # Classe con indice numerico 0\n",
    "    \"NCR/NET\",              # Classe con indice numerico 1 (Nucleo Necrotico/Non-Enhancing)\n",
    "    \"Edema (ED)\",           # Classe con indice numerico 2\n",
    "    \"Tumore Enhancing (ET)\" # Classe con indice numerico 3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d237a-df0f-43e1-93a5-687322ded71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CONFIGURAZIONE E ESECUZIONE GNNEXPLAINER PER UN NODO SPECIFICO ---\n",
      "Nodo target selezionato per la spiegazione: Indice 847\n",
      "  Classe Predetta: Tumore Enhancing (ET) (Indice: 3)\n",
      "  Classe Reale:    Tumore Enhancing (ET) (Indice: 3)\n",
      "\n",
      "Inizio generazione spiegazione per il nodo: 847...\n"
     ]
    }
   ],
   "source": [
    "# ----- INIZIO CELLA 9 (O LA TUA CELLA DI SPIEGABILITÀ) -----\n",
    "\n",
    "# Assicurati che le variabili `model`, `data`, `predicted_labels`, `num_node_features`, `classes`\n",
    "# siano già definite e caricate correttamente dalle celle precedenti.\n",
    "\n",
    "# 0. Importazioni necessarie (se non già presenti all'inizio del notebook)\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.explain import Explainer, ModelConfig # ThresholdConfig non lo usiamo subito qui\n",
    "from torch_geometric.explain.algorithm import GNNExplainer\n",
    "\n",
    "print(\"\\n--- CONFIGURAZIONE E ESECUZIONE GNNEXPLAINER PER UN NODO SPECIFICO ---\")\n",
    "\n",
    "# 1. Selezionare un NODO TARGET da spiegare\n",
    "target_class_value_for_explanation = 3  # Esempio: ET. Puoi cambiarlo.\n",
    "node_to_explain_index = -1\n",
    "\n",
    "# Controlla se predicted_labels esiste (dovrebbe dalla cella precedente)\n",
    "if 'predicted_labels' not in locals() or not isinstance(predicted_labels, torch.Tensor):\n",
    "    raise NameError(\"La variabile 'predicted_labels' non è definita. Esegui la cella dove calcoli le predizioni.\")\n",
    "\n",
    "candidate_indices = (predicted_labels == target_class_value_for_explanation).nonzero(as_tuple=True)[0]\n",
    "\n",
    "if len(candidate_indices) > 0:\n",
    "    node_to_explain_index = candidate_indices[random.randint(0, len(candidate_indices)-1)].item() # Scegli un candidato a caso\n",
    "    print(f\"Nodo target selezionato per la spiegazione: Indice {node_to_explain_index}\")\n",
    "    pred_class_idx = int(predicted_labels[node_to_explain_index].item())\n",
    "    print(f\"  Classe Predetta: {classes[pred_class_idx]} (Indice: {pred_class_idx})\")\n",
    "    if data.y is not None and node_to_explain_index < len(data.y):\n",
    "        real_class_idx = int(data.y[node_to_explain_index].item())\n",
    "        print(f\"  Classe Reale:    {classes[real_class_idx]} (Indice: {real_class_idx})\")\n",
    "    else:\n",
    "        print(f\"  Classe Reale:    non disponibile per il nodo {node_to_explain_index}.\")\n",
    "else:\n",
    "    if data.num_nodes > 0:\n",
    "        node_to_explain_index = random.randint(0, data.num_nodes - 1) # Fallback\n",
    "        print(f\"Nessun nodo trovato per la classe target {target_class_value_for_explanation}. Si spiega il nodo casuale: Indice {node_to_explain_index}\")\n",
    "        pred_class_idx = int(predicted_labels[node_to_explain_index].item())\n",
    "        print(f\"  Classe Predetta per fallback: {classes[pred_class_idx]} (Indice: {pred_class_idx})\")\n",
    "        if data.y is not None and node_to_explain_index < len(data.y):\n",
    "            real_class_idx = int(data.y[node_to_explain_index].item())\n",
    "            print(f\"  Classe Reale per fallback:    {classes[real_class_idx]} (Indice: {real_class_idx})\")\n",
    "        else:\n",
    "            print(f\"  Classe Reale per fallback:    non disponibile per il nodo {node_to_explain_index}.\")\n",
    "    else:\n",
    "        raise ValueError(\"Il grafo caricato non ha nodi.\")\n",
    "\n",
    "\n",
    "# 2. Configurare l'Algoritmo GNNExplainer\n",
    "gnn_explainer_algorithm = GNNExplainer(\n",
    "    epochs=200,\n",
    "    lr=0.01,\n",
    "    coeffs={ # Questi coefficienti aiutano a ottenere spiegazioni più \"pulite\"\n",
    "        \"edge_size\": 0.005,\n",
    "        \"node_feat_size\": 1.0, # Meno penalità sull'uso delle feature per una spiegazione basata su feature\n",
    "        \"edge_ent\": 1.0,\n",
    "        \"node_feat_ent\": 0.1,\n",
    "    }\n",
    "    # return_type='raw' # Default è 'raw' che si aspetta logits.\n",
    "                        # Se il tuo modello ha LogSoftmax, GNNExplainer può avere problemi a convergere.\n",
    "                        # Potrebbe essere necessario passare l'output del modello (logits) direttamente\n",
    "                        # o assicurarsi che `model_config.return_type` sia gestito correttamente.\n",
    ")\n",
    "\n",
    "# 3. Configurare l'Oggetto `Explainer` generale\n",
    "model_config = ModelConfig(\n",
    "    mode=\"multiclass_classification\",\n",
    "    task_level=\"node\",\n",
    "    return_type=\"log_probs\",  # DEVE corrispondere all'output di model(data.x, data.edge_index)\n",
    "                              # Se il modello restituisce logits, cambia questo in \"raw\"\n",
    ")\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model, # Il tuo modello ChebNet pre-addestrato\n",
    "    algorithm=gnn_explainer_algorithm,\n",
    "    explanation_type=\"phenomenon\",     # <-- Chiave per il tuo obiettivo!\n",
    "    model_config=model_config,\n",
    "    node_mask_type=\"attributes\",       # Vogliamo importanza delle FEATURES\n",
    "    edge_mask_type=\"object\",           # Vogliamo importanza degli ARCHI (quindi vicini)\n",
    "    # Non usare threshold_config qui per ora, analizza le maschere grezze.\n",
    ")\n",
    "\n",
    "# 4. Generare la Spiegazione per il Nodo Target Selezionato\n",
    "print(f\"\\nInizio generazione spiegazione per il nodo: {node_to_explain_index}...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Per spiegare la predizione del modello PER IL NODO SCELTO, usa predicted_labels\n",
    "# Se volessi spiegare rispetto alla ground truth, useresti data.y\n",
    "target_for_explanation = predicted_labels.type(torch.LongTensor) # Usa TUTTE le etichette (predette)\n",
    "                                                                  # GNNExplainer userà 'index' per selezionare.\n",
    "\n",
    "explanation = explainer(\n",
    "    x=data.x,\n",
    "    edge_index=data.edge_index.type(torch.int64), # Assicurati sia LongTensor\n",
    "    index=node_to_explain_index,                  # Il NODO specifico da spiegare\n",
    "    target=target_for_explanation                 # Il tensore completo delle etichette target (predette)\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Spiegazione per il nodo {node_to_explain_index} generata in {elapsed_time:.2f} secondi.\")\n",
    "\n",
    "# 5. DEBUG Iniziale: Stampa informazioni sulle maschere ottenute\n",
    "print(\"\\n--- INFORMAZIONI SULLA SPIEGAZIONE GENERATA (DEBUG) ---\")\n",
    "if hasattr(explanation, 'node_mask') and explanation.node_mask is not None:\n",
    "    print(f\"Forma di explanation.node_mask: {explanation.node_mask.shape}\")\n",
    "    # Dovrebbe essere [N_nodi_nel_sottografo, num_node_features] o simile.\n",
    "    # O [num_node_features] se l'algoritmo è ottimizzato per dare solo quelle del target.\n",
    "    # Il tuo output precedente era [2607, 50], che è [data.num_nodes, num_node_features]\n",
    "    # Questo significa che hai l'importanza delle features per OGNI nodo nel contesto della\n",
    "    # spiegazione del nodo target.\n",
    "    if explanation.node_mask.numel() > 0:\n",
    "        # Estraiamo l'importanza delle features PER IL NODO TARGET\n",
    "        target_node_feature_mask = explanation.node_mask[node_to_explain_index]\n",
    "        print(f\"Valori di explanation.node_mask PER NODO TARGET {node_to_explain_index} (prime 5 features): {target_node_feature_mask.squeeze()[:5]}\")\n",
    "else:\n",
    "    print(\"explanation.node_mask è None o non presente.\")\n",
    "\n",
    "if hasattr(explanation, 'edge_mask') and explanation.edge_mask is not None:\n",
    "    print(f\"Forma di explanation.edge_mask: {explanation.edge_mask.shape}\")\n",
    "    # Dovrebbe essere [N_archi_nel_sottografo]\n",
    "    if explanation.edge_mask.numel() > 0:\n",
    "        print(f\"Valori di explanation.edge_mask (prime 5 archi importanti): {explanation.edge_mask[:5]}\")\n",
    "else:\n",
    "    print(\"explanation.edge_mask è None o non presente.\")\n",
    "\n",
    "# Indici dei nodi e archi del sottografo esplicativo (se GNNExplainer li popola)\n",
    "if hasattr(explanation, 'node_idx') and explanation.node_idx is not None:\n",
    "    print(f\"Indici dei nodi nel sottografo esplicativo (explanation.node_idx): {explanation.node_idx}\")\n",
    "    print(f\"  Numero di nodi nel sottografo: {len(explanation.node_idx)}\")\n",
    "else:\n",
    "    print(\"explanation.node_idx non presente. Questo potrebbe significare che le maschere si riferiscono al grafo completo, ma con valori non nulli solo per il sottografo rilevante.\")\n",
    "\n",
    "if hasattr(explanation, 'edge_index') and explanation.edge_index is not None:\n",
    "    print(f\"Archi nel sottografo esplicativo (explanation.edge_index, forma {explanation.edge_index.shape}):\")\n",
    "    if explanation.edge_index.numel() > 0 :\n",
    "        print(f\"  (Primi 5 archi del sottografo, se presenti): \\n{explanation.edge_index[:,:5]}\")\n",
    "    else:\n",
    "        print(\"  Nessun arco restituito in explanation.edge_index.\")\n",
    "else:\n",
    "    print(\"explanation.edge_index non presente.\")\n",
    "\n",
    "# ----- FINE CELLA 9 (O LA TUA CELLA DI SPIEGABILITÀ) -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1cb7a-d104-44d9-931f-9419d8fe90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- INIZIO NUOVA CELLA PER PLOT FEATURES NODO TARGET -----\n",
    "\n",
    "if hasattr(explanation, 'node_mask') and explanation.node_mask is not None and \\\n",
    "   explanation.node_mask.shape[0] == data.num_nodes and \\\n",
    "   explanation.node_mask.shape[1] == num_node_features:\n",
    "\n",
    "    target_node_feature_importances = explanation.node_mask[node_to_explain_index].cpu().detach().numpy()\n",
    "\n",
    "    print(f\"\\nVisualizzazione dell'Importanza delle {num_node_features} features per il NODO TARGET {node_to_explain_index}:\")\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    bar_positions = np.arange(num_node_features)\n",
    "    plt.bar(bar_positions, target_node_feature_importances)\n",
    "    plt.xlabel(\"Indice della Feature\")\n",
    "    plt.xticks(bar_positions[::5]) # Mostra un tick ogni 5 feature per leggibilità\n",
    "    plt.ylabel(\"Importanza (da GNNExplainer)\")\n",
    "    plt.title(f\"Importanza delle Features per Nodo Target {node_to_explain_index} (Classe Pred: {classes[predicted_labels[node_to_explain_index].item()]})\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Stampa le top K features più importanti\n",
    "    k_top_features = 10\n",
    "    # sorted_feature_indices = np.argsort(target_node_feature_importances)[::-1] # Decrescente\n",
    "    sorted_feature_indices = np.flip(np.argsort(target_node_feature_importances)) # Corretto per evitare problemi di stride\n",
    "    \n",
    "    print(f\"\\nTop {k_top_features} features più importanti per il nodo {node_to_explain_index}:\")\n",
    "    # Se hai una lista `feature_names` di lunghezza `num_node_features`, usala qui!\n",
    "    # Esempio: feature_names = [f\"Feature_{i}\" for i in range(num_node_features)]\n",
    "    for i in range(min(k_top_features, num_node_features)):\n",
    "        feat_idx = sorted_feature_indices[i]\n",
    "        importance = target_node_feature_importances[feat_idx]\n",
    "        # feat_name = feature_names[feat_idx] # Se hai feature_names\n",
    "        print(f\"  Feature {feat_idx}: Importanza = {importance:.4f}\")\n",
    "else:\n",
    "    print(\"Formato di 'explanation.node_mask' non come atteso ([data.num_nodes, num_node_features]) per l'analisi delle feature del nodo target.\")\n",
    "    print(\"Oppure 'explanation.node_mask' è None.\")\n",
    "\n",
    "# ----- FINE NUOVA CELLA PER PLOT FEATURES NODO TARGET -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf2e4f-cd21-4b86-a87d-bcc7e8dc460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- INIZIO CELLA PER ANALISI ARCHI E VICINI IMPORTANTI (FOCALIZZATA SUL TARGET) -----\n",
    "\n",
    "if hasattr(explanation, 'edge_mask') and explanation.edge_mask is not None:\n",
    "    edge_importances_np = explanation.edge_mask.cpu().detach().numpy()\n",
    "    original_graph_edges_np = data.edge_index.cpu().detach().numpy() # Archi originali del grafo\n",
    "\n",
    "    if original_graph_edges_np.shape[1] != len(edge_importances_np):\n",
    "        print(f\"ATTENZIONE: Il numero di archi in data.edge_index ({original_graph_edges_np.shape[1]}) \"\n",
    "              f\"non corrisponde alla lunghezza di explanation.edge_mask ({len(edge_importances_np)}). L'analisi degli archi non può procedere correttamente.\")\n",
    "    else:\n",
    "        print(f\"\\n--- Analisi degli Archi e Vicini Importanti per il NODO TARGET: {node_to_explain_index} ---\")\n",
    "        \n",
    "        # 1. Estrarre tutti gli archi connessi al nodo target e la loro importanza\n",
    "        #    (Questa parte è già nel tuo codice precedente e la riutilizziamo)\n",
    "        connected_edges_info = [] # Lista di tuple: (importance, node_u, node_v)\n",
    "        for i in range(original_graph_edges_np.shape[1]):\n",
    "            node_u = int(original_graph_edges_np[0, i])\n",
    "            node_v = int(original_graph_edges_np[1, i])\n",
    "            importance = edge_importances_np[i]\n",
    "\n",
    "            if node_u == node_to_explain_index or node_v == node_to_explain_index:\n",
    "                connected_edges_info.append((importance, node_u, node_v))\n",
    "        \n",
    "        # 2. Ordina gli archi CONNESSI AL TARGET per importanza (decrescente)\n",
    "        connected_edges_info.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        k_top_connected_edges_to_show = 15 # Quanti archi connessi al target mostrare\n",
    "        \n",
    "        print(f\"\\nTop {k_top_connected_edges_to_show} archi più importanti CONNESSI al nodo target {node_to_explain_index}:\")\n",
    "        print(f\"{'Arco (u, v)':<15} {'Importanza':<15} {'Classe Nodo U':<25} {'Classe Nodo V':<25}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        if not connected_edges_info:\n",
    "            print(f\"Nessun arco con importanza > 0 trovato direttamente connesso al nodo target {node_to_explain_index}.\")\n",
    "        else:\n",
    "            important_neighbors_of_target = {}\n",
    "            # Mostra solo i top k_top_connected_edges_to_show archi *che sono connessi al target*\n",
    "            for i in range(min(k_top_connected_edges_to_show, len(connected_edges_info))):\n",
    "                importance, node_u, node_v = connected_edges_info[i]\n",
    "                \n",
    "                # Assicurati che predicted_labels e classes siano definiti\n",
    "                class_u_idx = int(predicted_labels[node_u].item())\n",
    "                class_v_idx = int(predicted_labels[node_v].item())\n",
    "                class_u_str = classes[class_u_idx]\n",
    "                class_v_str = classes[class_v_idx]\n",
    "                \n",
    "                print(f\"({node_u}-{node_v}){'':<5} {importance:<15.4f} {class_u_str:<25} {class_v_str:<25}\")\n",
    "\n",
    "                # Identifica il vicino e aggrega la sua importanza\n",
    "                neighbor_node_idx = node_v if node_u == node_to_explain_index else node_u\n",
    "                important_neighbors_of_target[neighbor_node_idx] = important_neighbors_of_target.get(neighbor_node_idx, 0) + importance\n",
    "            \n",
    "            if important_neighbors_of_target:\n",
    "                print(f\"\\nTop Vicini più influenti per il nodo target {node_to_explain_index} (basato su importanza archi connessi):\")\n",
    "                # Ordina i vicini per importanza aggregata\n",
    "                sorted_direct_neighbors = sorted(important_neighbors_of_target.items(), key=lambda item: item[1], reverse=True)\n",
    "                for neighbor_idx_int, total_importance in sorted_direct_neighbors[:10]: # Mostra i top 10 vicini\n",
    "                    class_neighbor_idx = int(predicted_labels[neighbor_idx_int].item())\n",
    "                    print(f\"  Vicino {neighbor_idx_int} (Classe Predetta: {classes[class_neighbor_idx]}): Importanza Aggreg. Archi = {total_importance:.4f}\")\n",
    "            else:\n",
    "                print(f\"Nessun vicino significativo identificato per il nodo {node_to_explain_index} dai top archi connessi.\")\n",
    "\n",
    "        # ----- Inizio Sezione Visualizzazione NetworkX (OPZIONALE) -----\n",
    "        if important_neighbors_of_target: # Visualizza solo se ci sono vicini importanti\n",
    "            try:\n",
    "                import networkx as nx\n",
    "                # import matplotlib.pyplot as plt # Assicurati sia importato\n",
    "                \n",
    "                plt.figure(figsize=(12, 10))\n",
    "                vis_graph = nx.Graph()\n",
    "                \n",
    "                # Nodi da includere nella visualizzazione: il target e i suoi vicini importanti\n",
    "                nodes_to_visualize_set = {node_to_explain_index}.union(set(important_neighbors_of_target.keys()))\n",
    "                \n",
    "                node_labels_vis = {}\n",
    "                node_color_list_vis = []\n",
    "                \n",
    "                # Palette di colori (definisci 'discrete_colors_for_classes' come suggerito prima)\n",
    "                cmap_for_plot = plt.get_cmap('viridis')\n",
    "                discrete_colors_for_classes = [cmap_for_plot(i / (num_classes - 1)) for i in range(num_classes)]\n",
    "\n",
    "                for node_idx in list(nodes_to_visualize_set):\n",
    "                    vis_graph.add_node(node_idx)\n",
    "                    pred_class_idx = int(predicted_labels[node_idx].item())\n",
    "                    node_labels_vis[node_idx] = f\"{node_idx}\\n({classes[pred_class_idx]})\"\n",
    "                    if node_idx == node_to_explain_index:\n",
    "                        node_color_list_vis.append('red')\n",
    "                    elif 0 <= pred_class_idx < num_classes:\n",
    "                        node_color_list_vis.append(discrete_colors_for_classes[pred_class_idx])\n",
    "                    else:\n",
    "                        node_color_list_vis.append('grey') # Fallback\n",
    "\n",
    "                # Archi da disegnare: solo quelli tra il nodo target e i suoi vicini importanti\n",
    "                # (che sono già in `connected_edges_info` e filtrati da `important_neighbors_of_target`)\n",
    "                edges_to_visualize = []\n",
    "                edge_weights_visualize = []\n",
    "\n",
    "                for importance_val, u, v in connected_edges_info: # Itera sugli archi già connessi al target e ordinati\n",
    "                    if u in nodes_to_visualize_set and v in nodes_to_visualize_set: # Assicura che entrambi siano nel nostro set\n",
    "                        # Limita al numero di top archi connessi da visualizzare\n",
    "                        if len(edges_to_visualize) < k_top_connected_edges_to_show :\n",
    "                            edges_to_visualize.append((u, v))\n",
    "                            edge_weights_visualize.append(max(0.1, importance_val * 7)) # Scala importanza per spessore\n",
    "                        else:\n",
    "                            break \n",
    "                \n",
    "                vis_graph.add_edges_from(edges_to_visualize)\n",
    "\n",
    "                if vis_graph.number_of_nodes() > 0:\n",
    "                    pos = nx.spring_layout(vis_graph, k=0.7, iterations=40)\n",
    "                    nx.draw(vis_graph, pos, labels=node_labels_vis, with_labels=True, \n",
    "                            node_color=node_color_list_vis, node_size=1500, font_size=9, \n",
    "                            width=edge_weights_visualize, font_color='black', edge_color='darkgrey',\n",
    "                            alpha=0.9)\n",
    "                    plt.title(f\"Sottografo Locale Esplicativo per Nodo {node_to_explain_index} (Rosso=Target)\", fontsize=15)\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(f\"Sottografo per la visualizzazione è vuoto per il nodo {node_to_explain_index}.\")\n",
    "\n",
    "            except ImportError:\n",
    "                print(\"NetworkX non è installato. Salta la visualizzazione del sottografo dei vicini.\")\n",
    "            except Exception as e_vis:\n",
    "                print(f\"Errore durante la visualizzazione del sottografo dei vicini: {e_vis}\")\n",
    "        # ----- Fine Sezione Visualizzazione NetworkX -----\n",
    "else:\n",
    "    print(\"Mancano `explanation.edge_mask` per l'analisi dettagliata degli archi.\")\n",
    "\n",
    "# ----- FINE CELLA PER ANALISI ARCHI E VICINI IMPORTANTI (FOCALIZZATA SUL TARGET) -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874375d9-4b89-4e5d-bc23-b6bbfa4d8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- INIZIO NUOVA CELLA PER ANALISI ARCHI E VICINI IMPORTANTI -----\n",
    "\n",
    "# Visualizzazione del sottografo importante (più avanzato, richiede NetworkX)\n",
    "# e analisi degli archi.\n",
    "# Dobbiamo usare `explanation.edge_mask` e `explanation.edge_index` (del sottografo)\n",
    "\n",
    "if hasattr(explanation, 'edge_mask') and explanation.edge_mask is not None and \\\n",
    "   hasattr(explanation, 'edge_index') and explanation.edge_index is not None:\n",
    "\n",
    "    edge_importances_np = explanation.edge_mask.cpu().detach().numpy()\n",
    "    subgraph_edges_np = explanation.edge_index.cpu().detach().numpy() # Forma [2, NumArchiSottografo]\n",
    "\n",
    "    if subgraph_edges_np.shape[1] != len(edge_importances_np):\n",
    "        print(f\"ATTENZIONE: Il numero di archi in explanation.edge_index ({subgraph_edges_np.shape[1]}) \"\n",
    "              f\"non corrisponde alla lunghezza di explanation.edge_mask ({len(edge_importances_np)}).\")\n",
    "        print(\"L'analisi degli archi potrebbe non essere corretta.\")\n",
    "    else:\n",
    "        print(f\"\\nAnalisi degli archi più importanti NEL SOTTOGRAFO ESPLICATIVO per il nodo {node_to_explain_index}:\")\n",
    "        k_top_edges_to_show = 15\n",
    "        # sorted_edge_indices_in_subgraph = np.argsort(edge_importances_np)[::-1]\n",
    "        sorted_edge_indices_in_subgraph = np.flip(np.argsort(edge_importances_np))\n",
    "\n",
    "\n",
    "        print(f\"{'Arco Sottografo (u_sub,v_sub)':<25} {'Importanza':<15} {'Nodo Orig. u':<15} {'Classe u':<20} {'Nodo Orig. v':<15} {'Classe v':<20}\")\n",
    "        print(\"-\" * 110)\n",
    "\n",
    "        # `explanation.node_idx` mappa gli indici del sottografo a quelli originali.\n",
    "        # Se `explanation.node_idx` è None, si assume che subgraph_edges_np usi già indici originali (improbabile)\n",
    "        # o che non si possa fare la mappatura diretta facilmente.\n",
    "        # Il tuo ultimo output diceva \"explanation.node_idx non presente.\"\n",
    "        # Questo è un problema per mappare i nodi del sottografo a quelli originali!\n",
    "\n",
    "        # CONTROLLIAMO SE `explanation` CONTIENE GLI INDICI DEI NODI DEL SOTTOGRAFO\n",
    "        subgraph_node_indices_original = None\n",
    "        if hasattr(explanation, 'node_idx') and explanation.node_idx is not None:\n",
    "            subgraph_node_indices_original = explanation.node_idx.cpu().detach().numpy()\n",
    "            print(f\"Trovato explanation.node_idx con {len(subgraph_node_indices_original)} nodi.\")\n",
    "        else:\n",
    "            print(\"ATTENZIONE: `explanation.node_idx` non è disponibile. Non è possibile mappare gli indici dei nodi del sottografo agli indici originali in modo affidabile con queste informazioni.\")\n",
    "            print(\"L'analisi dei 'vicini importanti' sarà limitata o potrebbe essere errata.\")\n",
    "            # Se questo succede, `subgraph_edges_np` potrebbe contenere indici originali\n",
    "            # e il \"sottografo\" è l'intero grafo, con `edge_mask` che rende la maggior parte degli archi non importanti.\n",
    "            # O, `subgraph_edges_np` è un sottografo ma non sappiamo a quali nodi originali si riferisce.\n",
    "\n",
    "        important_neighbors_of_target = {}\n",
    "\n",
    "        for i in range(min(k_top_edges_to_show, len(sorted_edge_indices_in_subgraph))):\n",
    "            idx_in_mask_and_subgraph_edges = sorted_edge_indices_in_subgraph[i]\n",
    "            importance = edge_importances_np[idx_in_mask_and_subgraph_edges]\n",
    "            \n",
    "            # Nodi u e v come appaiono in subgraph_edges_np\n",
    "            # Questi sono indici RELATIVI ai nodi presenti in subgraph_node_indices_original,\n",
    "            # se subgraph_node_indices_original è definito.\n",
    "            node_u_sub_idx = subgraph_edges_np[0, idx_in_mask_and_subgraph_edges]\n",
    "            node_v_sub_idx = subgraph_edges_np[1, idx_in_mask_and_subgraph_edges]\n",
    "\n",
    "            # Mappa a indici originali se possibile\n",
    "            node_u_orig, node_v_orig = \"?\", \"?\"\n",
    "            class_u_str, class_v_str = \"N/A\", \"N/A\"\n",
    "\n",
    "            if subgraph_node_indices_original is not None:\n",
    "                if node_u_sub_idx < len(subgraph_node_indices_original):\n",
    "                    node_u_orig = subgraph_node_indices_original[node_u_sub_idx]\n",
    "                    class_u_str = classes[predicted_labels[node_u_orig].item()]\n",
    "                if node_v_sub_idx < len(subgraph_node_indices_original):\n",
    "                    node_v_orig = subgraph_node_indices_original[node_v_sub_idx]\n",
    "                    class_v_str = classes[predicted_labels[node_v_orig].item()]\n",
    "            else:\n",
    "                # Se node_idx non c'è, proviamo a interpretare u e v come indici originali\n",
    "                # Questo è probabile se GNNExplainer ha dato una edge_mask per TUTTI gli archi originali\n",
    "                # e explanation.edge_index è semplicemente data.edge_index (ma GNNExplainer di solito lo filtra).\n",
    "                # Questo caso è meno probabile con la nuova API Explainer per \"phenomenon\".\n",
    "                # Assumiamo che gli indici in subgraph_edges_np SIANO originali se node_idx non c'è\n",
    "                # (con cautela, perché potrebbe essere errato).\n",
    "                node_u_orig = node_u_sub_idx\n",
    "                node_v_orig = node_v_sub_idx\n",
    "                if node_u_orig < data.num_nodes: class_u_str = classes[predicted_labels[node_u_orig].item()]\n",
    "                if node_v_orig < data.num_nodes: class_v_str = classes[predicted_labels[node_v_orig].item()]\n",
    "\n",
    "\n",
    "            is_direct_neighbor_of_target = False\n",
    "            if node_u_orig == node_to_explain_index or node_v_orig == node_to_explain_index:\n",
    "                is_direct_neighbor_of_target = True\n",
    "                \n",
    "                neighbor_node_idx = node_v_orig if node_u_orig == node_to_explain_index else node_u_orig\n",
    "                if isinstance(neighbor_node_idx, int): # Assicurati che sia un indice valido\n",
    "                     important_neighbors_of_target[neighbor_node_idx] = important_neighbors_of_target.get(neighbor_node_idx, 0) + importance\n",
    "\n",
    "            direct_flag = \"*\" if is_direct_neighbor_of_target else \" \"\n",
    "            print(f\"{direct_flag}({node_u_sub_idx}-{node_v_sub_idx}){'':<5} {importance:<15.4f} {str(node_u_orig):<15} {class_u_str:<20} {str(node_v_orig):<15} {class_v_str:<20}\")\n",
    "\n",
    "        if important_neighbors_of_target:\n",
    "            print(f\"\\nVicini più importanti del nodo target {node_to_explain_index} (e la loro importanza aggregata dagli archi):\")\n",
    "            sorted_direct_neighbors = sorted(important_neighbors_of_target.items(), key=lambda item: item[1], reverse=True)\n",
    "            for neighbor, total_importance in sorted_direct_neighbors[:10]:\n",
    "                print(f\"  Vicino {neighbor} (Classe: {classes[predicted_labels[neighbor].item()]}): Imp. Aggregata Archi = {total_importance:.4f}\")\n",
    "\n",
    "        # (La visualizzazione con NetworkX andrebbe qui, se decidi di implementarla)\n",
    "\n",
    "else:\n",
    "    print(\"Mancano edge_mask o edge_index per analizzare gli archi importanti.\")\n",
    "\n",
    "# ----- FINE NUOVA CELLA PER ANALISI ARCHI E VICINI IMPORTANTI -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b99ca-c898-4b6f-8d04-bdc098dcae37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
